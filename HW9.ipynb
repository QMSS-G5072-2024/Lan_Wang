{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8dac1d-df0a-4eac-95bd-cf023bd8b4b7",
   "metadata": {},
   "source": [
    "# Web Scraping with Selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05165c4-8c99-478f-a2ab-b8dfbdeea82e",
   "metadata": {},
   "source": [
    "## 1. Create a Function to Scrape Company Infoboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2425ff-3815-42f2-adee-88526769cb36",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddd4b937-cb85-42af-891c-e483dec3e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as p\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf9a1e30-8e0b-469f-b5f1-2313873ad0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_billion(value):\n",
    "    \"\"\"Normalize monetary values to billions of USD.\"\"\"\n",
    "    if not value:\n",
    "        return None\n",
    "    try:\n",
    "        value = value.replace(\",\", \"\").replace(\"$\", \"\").lower()\n",
    "        if \"billion\" in value:\n",
    "            return float(re.search(r\"\\d+(\\.\\d+)?\", value).group())\n",
    "        elif \"million\" in value:\n",
    "            return float(re.search(r\"\\d+(\\.\\d+)?\", value).group()) / 1000\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1af4d48c-c478-4b84-8a38-5ac2de9447f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_info(wikipedia_url):\n",
    "    \"\"\"\n",
    "    Extracts basic company information such as revenue, industry, etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Request the page\n",
    "        response = requests.get(wikipedia_url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Locate the infobox\n",
    "        infobox = soup.find(\"table\", class_=lambda x: x and \"infobox\" in x)\n",
    "        if not infobox:\n",
    "            print(\"Infobox not found.\")\n",
    "            return None\n",
    "\n",
    "        # Initialize data dictionary\n",
    "        data = {\n",
    "            \"Company Name\": None,\n",
    "            \"Industry\": None,\n",
    "            \"Revenue (Billions USD)\": None,\n",
    "            \"Net Income (Billions USD)\": None,\n",
    "            \"Number of Employees\": None,\n",
    "            \"Market Cap (Billions USD)\": None,\n",
    "        }\n",
    "\n",
    "        # Extract rows from the infobox\n",
    "        rows = infobox.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            header = row.find(\"th\")\n",
    "            if header:\n",
    "                header_text = header.text.strip().lower()\n",
    "                value_cell = row.find(\"td\")\n",
    "                if value_cell:\n",
    "                    value_text = value_cell.text.strip()\n",
    "                    \n",
    "                    if \"industry\" in header_text:\n",
    "                        industries = re.split(r\"(?<=[a-z])(?=[A-Z])|\\n\", value_text)\n",
    "                        data[\"Industry\"] = \", \".join([industry.strip() for industry in industries])\n",
    "                    elif \"revenue\" in header_text:\n",
    "                        data[\"Revenue (Billions USD)\"] = normalize_to_billion(value_text)\n",
    "                    elif \"net income\" in header_text:\n",
    "                        data[\"Net Income (Billions USD)\"] = normalize_to_billion(value_text)\n",
    "                    elif \"number of employees\" in header_text:\n",
    "                        employee_match = re.search(r\"\\b\\d{1,3}(?:,\\d{3})*\\b\", value_text)\n",
    "                        data[\"Number of Employees\"] = employee_match.group(0).replace(\",\", \"\") if employee_match else None\n",
    "                    elif \"market cap\" in header_text:\n",
    "                        data[\"Market Cap (Billions USD)\"] = normalize_to_billion(value_text)\n",
    "\n",
    "        # Set Company Name\n",
    "        company_name = soup.find(\"h1\", {\"id\": \"firstHeading\"}).text\n",
    "        data[\"Company Name\"] = company_name\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_company_info: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b8a2885-0564-40d1-8145-53d57bff3d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': 'Apple Inc.', 'Industry': 'Consumer electronics, Software services, Online services', 'Revenue (Billions USD)': 391.04, 'Net Income (Billions USD)': 93.74, 'Number of Employees': '164000', 'Market Cap (Billions USD)': None}\n"
     ]
    }
   ],
   "source": [
    "# Testing with Apple Inc.\n",
    "apple_url = \"https://en.wikipedia.org/wiki/Apple_Inc.\"\n",
    "apple_info = get_company_info(apple_url)\n",
    "print(apple_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d82955-0509-495c-87c8-44ab2d0d9c39",
   "metadata": {},
   "source": [
    "### b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd590aca-31fc-4b4d-ac78-9488af15d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_company_info_with_key_people(data, infobox):\n",
    "    \"\"\"\n",
    "    Expands the company data dictionary with key people information:\n",
    "    CEO, Founder(s), and Founded (Year).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract rows from the infobox\n",
    "        rows = infobox.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            header = row.find(\"th\")\n",
    "            if header:\n",
    "                header_text = header.text.strip().lower()\n",
    "                value_cell = row.find(\"td\")\n",
    "                if value_cell:\n",
    "                    value_text = value_cell.text.strip()\n",
    "                    \n",
    "                    # CEO extraction\n",
    "                    if \"key people\" in header_text:\n",
    "                        # Split the key people section by newline or commas\n",
    "                        key_people = re.split(r\"\\n|, \", value_text)\n",
    "                        for person in key_people:\n",
    "                            if \"ceo\" in person.lower():\n",
    "                                ceo_match = re.search(r\"(.*?)(?=\\(|,|$)\", person)\n",
    "                                if ceo_match:\n",
    "                                    data[\"CEO\"] = ceo_match.group(1).strip()\n",
    "                                    break  # Stop after finding the CEO\n",
    "                    \n",
    "                    # Founder(s) extraction\n",
    "                    elif \"founder\" in header_text:\n",
    "                        # Use regex to split concatenated names or separators\n",
    "                        founders = re.split(r\"(?:\\s{2,}|\\n|,| and )\", value_text)\n",
    "                        data[\"Founder(s)\"] = \", \".join([founder.strip() for founder in founders if founder.strip()])\n",
    "                    \n",
    "                    # Founded (Year) extraction\n",
    "                    elif \"founded\" in header_text:\n",
    "                        year_match = re.search(r\"\\b(1[89]|20)\\d{2}\\b\", value_text)\n",
    "                        if year_match:\n",
    "                            data[\"Founded (Year)\"] = year_match.group()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while expanding key people information: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8910138-8e5f-4ad3-a605-b3317ad1a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_info_with_key_people(wikipedia_url):\n",
    "    \"\"\"\n",
    "    Combines the original get_company_info with expanded key people details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Request the page\n",
    "        response = requests.get(wikipedia_url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Locate the infobox\n",
    "        infobox = soup.find(\"table\", class_=lambda x: x and \"infobox\" in x)\n",
    "        if not infobox:\n",
    "            print(\"Infobox not found.\")\n",
    "            return None\n",
    "        \n",
    "        # Use the original function to extract basic data\n",
    "        data = get_company_info(wikipedia_url)\n",
    "\n",
    "        # Expand with key people information\n",
    "        expand_company_info_with_key_people(data, infobox)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_company_info_with_key_people: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89033e93-4313-41c6-b68a-353e17bdaab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': 'Apple Inc.', 'Industry': 'Consumer electronics, Software services, Online services', 'Revenue (Billions USD)': 391.04, 'Net Income (Billions USD)': 93.74, 'Number of Employees': '164000', 'Market Cap (Billions USD)': None, 'Founded (Year)': '1976', 'Founder(s)': 'Steve JobsSteve WozniakRonald Wayne', 'CEO': 'Arthur Levinson'}\n"
     ]
    }
   ],
   "source": [
    "# Testing with Apple Inc.\n",
    "apple_url = \"https://en.wikipedia.org/wiki/Apple_Inc.\"\n",
    "apple_info = get_company_info_with_key_people(apple_url)\n",
    "print(apple_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312efeb-44b0-4f17-8766-dac23a86fe32",
   "metadata": {},
   "source": [
    "## 2 Retrieve S&P 500 Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aae8b901-b1c8-4fdf-8f64-fb64bc147739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "906f00ec-8134-4302-8c0b-94e2714cc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the S&P 500 Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "# Send a GET request to fetch the content of the page\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the first table on the page (S&P 500 Constituents)\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Extract table rows contained in <tr> tags\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Extract data from the table rows\n",
    "data = []\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    cols = row.find_all('td')  # Extract each column (cell) in the row\n",
    "    if cols:  # Ensure the row has data\n",
    "        company_name = cols[1].text.strip()  # Correct column for company name\n",
    "        link = cols[1].find('a')['href'] if cols[1].find('a') else None  # Link to Wikipedia page\n",
    "        gics_sector = cols[2].text.strip()  # GICS sector\n",
    "        gics_sub_industry = cols[3].text.strip()  # GICS sub-industry\n",
    "        headquarters = cols[4].text.strip()  # Headquarters location\n",
    "        \n",
    "        # Append the row data\n",
    "        data.append([\n",
    "            company_name, \n",
    "            f\"https://en.wikipedia.org{link}\" if link else None,\n",
    "            gics_sector, \n",
    "            gics_sub_industry, \n",
    "            headquarters\n",
    "        ])\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"Company Name\", \n",
    "    \"Link to Company Wikipedia page\", \n",
    "    \"GICS Sector\", \n",
    "    \"GICS Sub-Industry\", \n",
    "    \"Headquarters Location\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f48ad061-4cdb-48f4-89ed-4d7effe42aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Company Name                     Link to Company Wikipedia page  \\\n",
      "0                   3M                   https://en.wikipedia.org/wiki/3M   \n",
      "1          A. O. Smith          https://en.wikipedia.org/wiki/A._O._Smith   \n",
      "2  Abbott Laboratories  https://en.wikipedia.org/wiki/Abbott_Laboratories   \n",
      "3               AbbVie               https://en.wikipedia.org/wiki/AbbVie   \n",
      "4            Accenture            https://en.wikipedia.org/wiki/Accenture   \n",
      "\n",
      "              GICS Sector               GICS Sub-Industry  \\\n",
      "0             Industrials        Industrial Conglomerates   \n",
      "1             Industrials               Building Products   \n",
      "2             Health Care           Health Care Equipment   \n",
      "3             Health Care                   Biotechnology   \n",
      "4  Information Technology  IT Consulting & Other Services   \n",
      "\n",
      "     Headquarters Location  \n",
      "0    Saint Paul, Minnesota  \n",
      "1     Milwaukee, Wisconsin  \n",
      "2  North Chicago, Illinois  \n",
      "3  North Chicago, Illinois  \n",
      "4          Dublin, Ireland  \n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59615b60-4454-43e9-acb5-43fda6fc92ee",
   "metadata": {},
   "source": [
    "## 3 Add Detailed Information to the S&P 500 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4f065f1-2d2e-4d9c-93de-23489add45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching details for 3M (1/503)...\n",
      "Fetching details for A. O. Smith (2/503)...\n",
      "Fetching details for Abbott Laboratories (3/503)...\n",
      "Fetching details for AbbVie (4/503)...\n",
      "Fetching details for Accenture (5/503)...\n",
      "Fetching details for Adobe Inc. (6/503)...\n",
      "Fetching details for Advanced Micro Devices (7/503)...\n",
      "Fetching details for AES Corporation (8/503)...\n",
      "Fetching details for Aflac (9/503)...\n",
      "Fetching details for Agilent Technologies (10/503)...\n",
      "Fetching details for Air Products (11/503)...\n",
      "Fetching details for Airbnb (12/503)...\n",
      "Fetching details for Akamai Technologies (13/503)...\n",
      "Fetching details for Albemarle Corporation (14/503)...\n",
      "Fetching details for Alexandria Real Estate Equities (15/503)...\n",
      "Fetching details for Align Technology (16/503)...\n",
      "Fetching details for Allegion (17/503)...\n",
      "Fetching details for Alliant Energy (18/503)...\n",
      "Fetching details for Allstate (19/503)...\n",
      "Fetching details for Alphabet Inc. (Class A) (20/503)...\n",
      "Fetching details for Alphabet Inc. (Class C) (21/503)...\n",
      "Fetching details for Altria (22/503)...\n",
      "Fetching details for Amazon (23/503)...\n",
      "Fetching details for Amcor (24/503)...\n",
      "Fetching details for Amentum (25/503)...\n",
      "Fetching details for Ameren (26/503)...\n",
      "Fetching details for American Electric Power (27/503)...\n",
      "Fetching details for American Express (28/503)...\n",
      "Fetching details for American International Group (29/503)...\n",
      "Fetching details for American Tower (30/503)...\n",
      "Fetching details for American Water Works (31/503)...\n",
      "Fetching details for Ameriprise Financial (32/503)...\n",
      "Fetching details for Ametek (33/503)...\n",
      "Fetching details for Amgen (34/503)...\n",
      "Fetching details for Amphenol (35/503)...\n",
      "Fetching details for Analog Devices (36/503)...\n",
      "Fetching details for Ansys (37/503)...\n",
      "Fetching details for Aon (38/503)...\n",
      "Fetching details for APA Corporation (39/503)...\n",
      "Fetching details for Apple Inc. (40/503)...\n",
      "Fetching details for Applied Materials (41/503)...\n",
      "Fetching details for Aptiv (42/503)...\n",
      "Fetching details for Arch Capital Group (43/503)...\n",
      "Fetching details for Archer Daniels Midland (44/503)...\n",
      "Fetching details for Arista Networks (45/503)...\n",
      "Fetching details for Arthur J. Gallagher & Co. (46/503)...\n",
      "Fetching details for Assurant (47/503)...\n",
      "Fetching details for AT&T (48/503)...\n",
      "Fetching details for Atmos Energy (49/503)...\n",
      "Fetching details for Autodesk (50/503)...\n",
      "Fetching details for Automatic Data Processing (51/503)...\n",
      "Fetching details for AutoZone (52/503)...\n",
      "Fetching details for AvalonBay Communities (53/503)...\n",
      "Fetching details for Avery Dennison (54/503)...\n",
      "Fetching details for Axon Enterprise (55/503)...\n",
      "Fetching details for Baker Hughes (56/503)...\n",
      "Fetching details for Ball Corporation (57/503)...\n",
      "Fetching details for Bank of America (58/503)...\n",
      "Fetching details for Baxter International (59/503)...\n",
      "Fetching details for Becton Dickinson (60/503)...\n",
      "Fetching details for Berkshire Hathaway (61/503)...\n",
      "Fetching details for Best Buy (62/503)...\n",
      "Fetching details for Bio-Techne (63/503)...\n",
      "Fetching details for Biogen (64/503)...\n",
      "Fetching details for BlackRock (65/503)...\n",
      "Fetching details for Blackstone Inc. (66/503)...\n",
      "Fetching details for BNY Mellon (67/503)...\n",
      "Fetching details for Boeing (68/503)...\n",
      "Fetching details for Booking Holdings (69/503)...\n",
      "Fetching details for BorgWarner (70/503)...\n",
      "Fetching details for Boston Scientific (71/503)...\n",
      "Fetching details for Bristol Myers Squibb (72/503)...\n",
      "Fetching details for Broadcom (73/503)...\n",
      "Fetching details for Broadridge Financial Solutions (74/503)...\n",
      "Fetching details for Brown & Brown (75/503)...\n",
      "Fetching details for Brown–Forman (76/503)...\n",
      "Fetching details for Builders FirstSource (77/503)...\n",
      "Fetching details for Bunge Global (78/503)...\n",
      "Fetching details for BXP, Inc. (79/503)...\n",
      "Fetching details for C.H. Robinson (80/503)...\n",
      "Fetching details for Cadence Design Systems (81/503)...\n",
      "Fetching details for Caesars Entertainment (82/503)...\n",
      "Fetching details for Camden Property Trust (83/503)...\n",
      "Fetching details for Campbell Soup Company (84/503)...\n",
      "Fetching details for Capital One (85/503)...\n",
      "Fetching details for Cardinal Health (86/503)...\n",
      "Fetching details for CarMax (87/503)...\n",
      "Fetching details for Carnival (88/503)...\n",
      "Fetching details for Carrier Global (89/503)...\n",
      "Fetching details for Catalent (90/503)...\n",
      "Fetching details for Caterpillar Inc. (91/503)...\n",
      "Fetching details for Cboe Global Markets (92/503)...\n",
      "Fetching details for CBRE Group (93/503)...\n",
      "Fetching details for CDW (94/503)...\n",
      "Fetching details for Celanese (95/503)...\n",
      "Fetching details for Cencora (96/503)...\n",
      "Fetching details for Centene Corporation (97/503)...\n",
      "Fetching details for CenterPoint Energy (98/503)...\n",
      "Fetching details for CF Industries (99/503)...\n",
      "Fetching details for Charles River Laboratories (100/503)...\n",
      "Fetching details for Charles Schwab Corporation (101/503)...\n",
      "Fetching details for Charter Communications (102/503)...\n",
      "Fetching details for Chevron Corporation (103/503)...\n",
      "Fetching details for Chipotle Mexican Grill (104/503)...\n",
      "Fetching details for Chubb Limited (105/503)...\n",
      "Fetching details for Church & Dwight (106/503)...\n",
      "Fetching details for Cigna (107/503)...\n",
      "Fetching details for Cincinnati Financial (108/503)...\n",
      "Fetching details for Cintas (109/503)...\n",
      "Fetching details for Cisco (110/503)...\n",
      "Fetching details for Citigroup (111/503)...\n",
      "Fetching details for Citizens Financial Group (112/503)...\n",
      "Fetching details for Clorox (113/503)...\n",
      "Fetching details for CME Group (114/503)...\n",
      "Fetching details for CMS Energy (115/503)...\n",
      "Fetching details for Coca-Cola Company (The) (116/503)...\n",
      "Fetching details for Cognizant (117/503)...\n",
      "Fetching details for Colgate-Palmolive (118/503)...\n",
      "Fetching details for Comcast (119/503)...\n",
      "Fetching details for Conagra Brands (120/503)...\n",
      "Fetching details for ConocoPhillips (121/503)...\n",
      "Fetching details for Consolidated Edison (122/503)...\n",
      "Fetching details for Constellation Brands (123/503)...\n",
      "Fetching details for Constellation Energy (124/503)...\n",
      "Fetching details for Cooper Companies (The) (125/503)...\n",
      "Fetching details for Copart (126/503)...\n",
      "Fetching details for Corning Inc. (127/503)...\n",
      "Fetching details for Corpay (128/503)...\n",
      "Fetching details for Corteva (129/503)...\n",
      "Fetching details for CoStar Group (130/503)...\n",
      "Fetching details for Costco (131/503)...\n",
      "Fetching details for Coterra (132/503)...\n",
      "Fetching details for CrowdStrike (133/503)...\n",
      "Fetching details for Crown Castle (134/503)...\n",
      "Fetching details for CSX Corporation (135/503)...\n",
      "Fetching details for Cummins (136/503)...\n",
      "Fetching details for CVS Health (137/503)...\n",
      "Fetching details for Danaher Corporation (138/503)...\n",
      "Fetching details for Darden Restaurants (139/503)...\n",
      "Fetching details for DaVita (140/503)...\n",
      "Fetching details for Dayforce (141/503)...\n",
      "Fetching details for Deckers Brands (142/503)...\n",
      "Fetching details for Deere & Company (143/503)...\n",
      "Fetching details for Dell Technologies (144/503)...\n",
      "Fetching details for Delta Air Lines (145/503)...\n",
      "Fetching details for Devon Energy (146/503)...\n",
      "Fetching details for Dexcom (147/503)...\n",
      "Fetching details for Diamondback Energy (148/503)...\n",
      "Fetching details for Digital Realty (149/503)...\n",
      "Fetching details for Discover Financial (150/503)...\n",
      "Fetching details for Dollar General (151/503)...\n",
      "Fetching details for Dollar Tree (152/503)...\n",
      "Fetching details for Dominion Energy (153/503)...\n",
      "Fetching details for Domino's (154/503)...\n",
      "Fetching details for Dover Corporation (155/503)...\n",
      "Fetching details for Dow Inc. (156/503)...\n",
      "Fetching details for D. R. Horton (157/503)...\n",
      "Fetching details for DTE Energy (158/503)...\n",
      "Fetching details for Duke Energy (159/503)...\n",
      "Fetching details for DuPont (160/503)...\n",
      "Fetching details for Eastman Chemical Company (161/503)...\n",
      "Fetching details for Eaton Corporation (162/503)...\n",
      "Fetching details for eBay (163/503)...\n",
      "Fetching details for Ecolab (164/503)...\n",
      "Fetching details for Edison International (165/503)...\n",
      "Fetching details for Edwards Lifesciences (166/503)...\n",
      "Fetching details for Electronic Arts (167/503)...\n",
      "Fetching details for Elevance Health (168/503)...\n",
      "Fetching details for Emerson Electric (169/503)...\n",
      "Fetching details for Enphase Energy (170/503)...\n",
      "Fetching details for Entergy (171/503)...\n",
      "Fetching details for EOG Resources (172/503)...\n",
      "Fetching details for EPAM Systems (173/503)...\n",
      "Fetching details for EQT Corporation (174/503)...\n",
      "Fetching details for Equifax (175/503)...\n",
      "Fetching details for Equinix (176/503)...\n",
      "Fetching details for Equity Residential (177/503)...\n",
      "Fetching details for Erie Indemnity (178/503)...\n",
      "Fetching details for Essex Property Trust (179/503)...\n",
      "Fetching details for Estée Lauder Companies (The) (180/503)...\n",
      "Fetching details for Everest Group (181/503)...\n",
      "Fetching details for Evergy (182/503)...\n",
      "Fetching details for Eversource Energy (183/503)...\n",
      "Fetching details for Exelon (184/503)...\n",
      "Fetching details for Expedia Group (185/503)...\n",
      "Fetching details for Expeditors International (186/503)...\n",
      "Fetching details for Extra Space Storage (187/503)...\n",
      "Fetching details for ExxonMobil (188/503)...\n",
      "Fetching details for F5, Inc. (189/503)...\n",
      "Fetching details for FactSet (190/503)...\n",
      "Fetching details for Fair Isaac (191/503)...\n",
      "Fetching details for Fastenal (192/503)...\n",
      "Fetching details for Federal Realty Investment Trust (193/503)...\n",
      "Fetching details for FedEx (194/503)...\n",
      "Fetching details for Fidelity National Information Services (195/503)...\n",
      "Fetching details for Fifth Third Bancorp (196/503)...\n",
      "Fetching details for First Solar (197/503)...\n",
      "Fetching details for FirstEnergy (198/503)...\n",
      "Fetching details for Fiserv (199/503)...\n",
      "Fetching details for FMC Corporation (200/503)...\n",
      "Fetching details for Ford Motor Company (201/503)...\n",
      "Fetching details for Fortinet (202/503)...\n",
      "Fetching details for Fortive (203/503)...\n",
      "Fetching details for Fox Corporation (Class A) (204/503)...\n",
      "Fetching details for Fox Corporation (Class B) (205/503)...\n",
      "Fetching details for Franklin Resources (206/503)...\n",
      "Fetching details for Freeport-McMoRan (207/503)...\n",
      "Fetching details for Garmin (208/503)...\n",
      "Fetching details for Gartner (209/503)...\n",
      "Fetching details for GE Aerospace (210/503)...\n",
      "Fetching details for GE HealthCare (211/503)...\n",
      "Fetching details for GE Vernova (212/503)...\n",
      "Fetching details for Gen Digital (213/503)...\n",
      "Fetching details for Generac (214/503)...\n",
      "Fetching details for General Dynamics (215/503)...\n",
      "Fetching details for General Mills (216/503)...\n",
      "Fetching details for General Motors (217/503)...\n",
      "Fetching details for Genuine Parts Company (218/503)...\n",
      "Fetching details for Gilead Sciences (219/503)...\n",
      "Fetching details for Global Payments (220/503)...\n",
      "Fetching details for Globe Life (221/503)...\n",
      "Fetching details for GoDaddy (222/503)...\n",
      "Fetching details for Goldman Sachs (223/503)...\n",
      "Fetching details for Halliburton (224/503)...\n",
      "Fetching details for Hartford (The) (225/503)...\n",
      "Fetching details for Hasbro (226/503)...\n",
      "Fetching details for HCA Healthcare (227/503)...\n",
      "Fetching details for Healthpeak Properties (228/503)...\n",
      "Fetching details for Henry Schein (229/503)...\n",
      "Fetching details for Hershey Company (The) (230/503)...\n",
      "Fetching details for Hess Corporation (231/503)...\n",
      "Fetching details for Hewlett Packard Enterprise (232/503)...\n",
      "Fetching details for Hilton Worldwide (233/503)...\n",
      "Fetching details for Hologic (234/503)...\n",
      "Fetching details for Home Depot (The) (235/503)...\n",
      "Fetching details for Honeywell (236/503)...\n",
      "Fetching details for Hormel Foods (237/503)...\n",
      "Fetching details for Host Hotels & Resorts (238/503)...\n",
      "Fetching details for Howmet Aerospace (239/503)...\n",
      "Fetching details for HP Inc. (240/503)...\n",
      "Fetching details for Hubbell Incorporated (241/503)...\n",
      "Fetching details for Humana (242/503)...\n",
      "Fetching details for Huntington Bancshares (243/503)...\n",
      "Fetching details for Huntington Ingalls Industries (244/503)...\n",
      "Fetching details for IBM (245/503)...\n",
      "Fetching details for IDEX Corporation (246/503)...\n",
      "Fetching details for Idexx Laboratories (247/503)...\n",
      "Fetching details for Illinois Tool Works (248/503)...\n",
      "Fetching details for Incyte (249/503)...\n",
      "Fetching details for Ingersoll Rand (250/503)...\n",
      "Fetching details for Insulet Corporation (251/503)...\n",
      "Error in get_company_info_with_key_people: 404 Client Error: Not Found for url: https://en.wikipedia.org/wiki/Insulet_Corporation\n",
      "Failed to retrieve data for Insulet Corporation: 'NoneType' object has no attribute 'get'\n",
      "Fetching details for Intel (252/503)...\n",
      "Fetching details for Intercontinental Exchange (253/503)...\n",
      "Fetching details for International Flavors & Fragrances (254/503)...\n",
      "Fetching details for International Paper (255/503)...\n",
      "Fetching details for Interpublic Group of Companies (The) (256/503)...\n",
      "Fetching details for Intuit (257/503)...\n",
      "Fetching details for Intuitive Surgical (258/503)...\n",
      "Fetching details for Invesco (259/503)...\n",
      "Fetching details for Invitation Homes (260/503)...\n",
      "Fetching details for IQVIA (261/503)...\n",
      "Fetching details for Iron Mountain (262/503)...\n",
      "Fetching details for J.B. Hunt (263/503)...\n",
      "Fetching details for Jabil (264/503)...\n",
      "Fetching details for Jack Henry & Associates (265/503)...\n",
      "Fetching details for Jacobs Solutions (266/503)...\n",
      "Fetching details for Johnson & Johnson (267/503)...\n",
      "Fetching details for Johnson Controls (268/503)...\n",
      "Fetching details for JPMorgan Chase (269/503)...\n",
      "Fetching details for Juniper Networks (270/503)...\n",
      "Fetching details for Kellanova (271/503)...\n",
      "Fetching details for Kenvue (272/503)...\n",
      "Fetching details for Keurig Dr Pepper (273/503)...\n",
      "Fetching details for KeyCorp (274/503)...\n",
      "Fetching details for Keysight Technologies (275/503)...\n",
      "Fetching details for Kimberly-Clark (276/503)...\n",
      "Fetching details for Kimco Realty (277/503)...\n",
      "Fetching details for Kinder Morgan (278/503)...\n",
      "Fetching details for KKR (279/503)...\n",
      "Fetching details for KLA Corporation (280/503)...\n",
      "Fetching details for Kraft Heinz (281/503)...\n",
      "Fetching details for Kroger (282/503)...\n",
      "Fetching details for L3Harris (283/503)...\n",
      "Fetching details for LabCorp (284/503)...\n",
      "Fetching details for Lam Research (285/503)...\n",
      "Fetching details for Lamb Weston (286/503)...\n",
      "Fetching details for Las Vegas Sands (287/503)...\n",
      "Fetching details for Leidos (288/503)...\n",
      "Fetching details for Lennar (289/503)...\n",
      "Fetching details for Lilly (Eli) (290/503)...\n",
      "Fetching details for Linde plc (291/503)...\n",
      "Fetching details for Live Nation Entertainment (292/503)...\n",
      "Fetching details for LKQ Corporation (293/503)...\n",
      "Fetching details for Lockheed Martin (294/503)...\n",
      "Fetching details for Loews Corporation (295/503)...\n",
      "Fetching details for Lowe's (296/503)...\n",
      "Fetching details for Lululemon Athletica (297/503)...\n",
      "Fetching details for LyondellBasell (298/503)...\n",
      "Fetching details for M&T Bank (299/503)...\n",
      "Fetching details for Marathon Petroleum (300/503)...\n",
      "Fetching details for MarketAxess (301/503)...\n",
      "Fetching details for Marriott International (302/503)...\n",
      "Fetching details for Marsh McLennan (303/503)...\n",
      "Fetching details for Martin Marietta Materials (304/503)...\n",
      "Fetching details for Masco (305/503)...\n",
      "Fetching details for Mastercard (306/503)...\n",
      "Fetching details for Match Group (307/503)...\n",
      "Fetching details for McCormick & Company (308/503)...\n",
      "Fetching details for McDonald's (309/503)...\n",
      "Fetching details for McKesson Corporation (310/503)...\n",
      "Fetching details for Medtronic (311/503)...\n",
      "Fetching details for Merck & Co. (312/503)...\n",
      "Fetching details for Meta Platforms (313/503)...\n",
      "Fetching details for MetLife (314/503)...\n",
      "Fetching details for Mettler Toledo (315/503)...\n",
      "Fetching details for MGM Resorts (316/503)...\n",
      "Fetching details for Microchip Technology (317/503)...\n",
      "Fetching details for Micron Technology (318/503)...\n",
      "Fetching details for Microsoft (319/503)...\n",
      "Fetching details for Mid-America Apartment Communities (320/503)...\n",
      "Fetching details for Moderna (321/503)...\n",
      "Fetching details for Mohawk Industries (322/503)...\n",
      "Fetching details for Molina Healthcare (323/503)...\n",
      "Fetching details for Molson Coors Beverage Company (324/503)...\n",
      "Fetching details for Mondelez International (325/503)...\n",
      "Fetching details for Monolithic Power Systems (326/503)...\n",
      "Fetching details for Monster Beverage (327/503)...\n",
      "Fetching details for Moody's Corporation (328/503)...\n",
      "Fetching details for Morgan Stanley (329/503)...\n",
      "Fetching details for Mosaic Company (The) (330/503)...\n",
      "Fetching details for Motorola Solutions (331/503)...\n",
      "Fetching details for MSCI (332/503)...\n",
      "Fetching details for Nasdaq, Inc. (333/503)...\n",
      "Fetching details for NetApp (334/503)...\n",
      "Fetching details for Netflix (335/503)...\n",
      "Fetching details for Newmont (336/503)...\n",
      "Fetching details for News Corp (Class A) (337/503)...\n",
      "Fetching details for News Corp (Class B) (338/503)...\n",
      "Fetching details for NextEra Energy (339/503)...\n",
      "Fetching details for Nike, Inc. (340/503)...\n",
      "Fetching details for NiSource (341/503)...\n",
      "Fetching details for Nordson Corporation (342/503)...\n",
      "Fetching details for Norfolk Southern Railway (343/503)...\n",
      "Fetching details for Northern Trust (344/503)...\n",
      "Fetching details for Northrop Grumman (345/503)...\n",
      "Fetching details for Norwegian Cruise Line Holdings (346/503)...\n",
      "Fetching details for NRG Energy (347/503)...\n",
      "Fetching details for Nucor (348/503)...\n",
      "Fetching details for Nvidia (349/503)...\n",
      "Fetching details for NVR, Inc. (350/503)...\n",
      "Fetching details for NXP Semiconductors (351/503)...\n",
      "Fetching details for O'Reilly Auto Parts (352/503)...\n",
      "Fetching details for Occidental Petroleum (353/503)...\n",
      "Fetching details for Old Dominion (354/503)...\n",
      "Fetching details for Omnicom Group (355/503)...\n",
      "Fetching details for ON Semiconductor (356/503)...\n",
      "Fetching details for ONEOK (357/503)...\n",
      "Fetching details for Oracle Corporation (358/503)...\n",
      "Fetching details for Otis Worldwide (359/503)...\n",
      "Fetching details for Paccar (360/503)...\n",
      "Fetching details for Packaging Corporation of America (361/503)...\n",
      "Fetching details for Palantir Technologies (362/503)...\n",
      "Fetching details for Palo Alto Networks (363/503)...\n",
      "Fetching details for Paramount Global (364/503)...\n",
      "Fetching details for Parker Hannifin (365/503)...\n",
      "Fetching details for Paychex (366/503)...\n",
      "Fetching details for Paycom (367/503)...\n",
      "Fetching details for PayPal (368/503)...\n",
      "Fetching details for Pentair (369/503)...\n",
      "Fetching details for PepsiCo (370/503)...\n",
      "Fetching details for Pfizer (371/503)...\n",
      "Fetching details for PG&E Corporation (372/503)...\n",
      "Fetching details for Philip Morris International (373/503)...\n",
      "Fetching details for Phillips 66 (374/503)...\n",
      "Fetching details for Pinnacle West (375/503)...\n",
      "Fetching details for PNC Financial Services (376/503)...\n",
      "Fetching details for Pool Corporation (377/503)...\n",
      "Fetching details for PPG Industries (378/503)...\n",
      "Fetching details for PPL Corporation (379/503)...\n",
      "Fetching details for Principal Financial Group (380/503)...\n",
      "Fetching details for Procter & Gamble (381/503)...\n",
      "Fetching details for Progressive Corporation (382/503)...\n",
      "Fetching details for Prologis (383/503)...\n",
      "Fetching details for Prudential Financial (384/503)...\n",
      "Fetching details for Public Service Enterprise Group (385/503)...\n",
      "Fetching details for PTC Inc. (386/503)...\n",
      "Fetching details for Public Storage (387/503)...\n",
      "Fetching details for PulteGroup (388/503)...\n",
      "Fetching details for Qorvo (389/503)...\n",
      "Fetching details for Quanta Services (390/503)...\n",
      "Fetching details for Qualcomm (391/503)...\n",
      "Fetching details for Quest Diagnostics (392/503)...\n",
      "Fetching details for Ralph Lauren Corporation (393/503)...\n",
      "Fetching details for Raymond James Financial (394/503)...\n",
      "Fetching details for RTX Corporation (395/503)...\n",
      "Fetching details for Realty Income (396/503)...\n",
      "Fetching details for Regency Centers (397/503)...\n",
      "Fetching details for Regeneron Pharmaceuticals (398/503)...\n",
      "Fetching details for Regions Financial Corporation (399/503)...\n",
      "Fetching details for Republic Services (400/503)...\n",
      "Fetching details for ResMed (401/503)...\n",
      "Fetching details for Revvity (402/503)...\n",
      "Fetching details for Rockwell Automation (403/503)...\n",
      "Fetching details for Rollins, Inc. (404/503)...\n",
      "Fetching details for Roper Technologies (405/503)...\n",
      "Fetching details for Ross Stores (406/503)...\n",
      "Fetching details for Royal Caribbean Group (407/503)...\n",
      "Fetching details for S&P Global (408/503)...\n",
      "Fetching details for Salesforce (409/503)...\n",
      "Fetching details for SBA Communications (410/503)...\n",
      "Fetching details for Schlumberger (411/503)...\n",
      "Fetching details for Seagate Technology (412/503)...\n",
      "Fetching details for Sempra (413/503)...\n",
      "Fetching details for ServiceNow (414/503)...\n",
      "Fetching details for Sherwin-Williams (415/503)...\n",
      "Fetching details for Simon Property Group (416/503)...\n",
      "Fetching details for Skyworks Solutions (417/503)...\n",
      "Fetching details for J.M. Smucker Company (The) (418/503)...\n",
      "Fetching details for Smurfit WestRock (419/503)...\n",
      "Fetching details for Snap-on (420/503)...\n",
      "Fetching details for Solventum (421/503)...\n",
      "Fetching details for Southern Company (422/503)...\n",
      "Fetching details for Southwest Airlines (423/503)...\n",
      "Fetching details for Stanley Black & Decker (424/503)...\n",
      "Fetching details for Starbucks (425/503)...\n",
      "Fetching details for State Street Corporation (426/503)...\n",
      "Fetching details for Steel Dynamics (427/503)...\n",
      "Fetching details for Steris (428/503)...\n",
      "Fetching details for Stryker Corporation (429/503)...\n",
      "Fetching details for Supermicro (430/503)...\n",
      "Fetching details for Synchrony Financial (431/503)...\n",
      "Fetching details for Synopsys (432/503)...\n",
      "Fetching details for Sysco (433/503)...\n",
      "Fetching details for T-Mobile US (434/503)...\n",
      "Fetching details for T. Rowe Price (435/503)...\n",
      "Fetching details for Take-Two Interactive (436/503)...\n",
      "Fetching details for Tapestry, Inc. (437/503)...\n",
      "Fetching details for Targa Resources (438/503)...\n",
      "Fetching details for Target Corporation (439/503)...\n",
      "Fetching details for TE Connectivity (440/503)...\n",
      "Fetching details for Teledyne Technologies (441/503)...\n",
      "Fetching details for Teleflex (442/503)...\n",
      "Fetching details for Teradyne (443/503)...\n",
      "Fetching details for Tesla, Inc. (444/503)...\n",
      "Fetching details for Texas Instruments (445/503)...\n",
      "Fetching details for Texas Pacific Land Corporation (446/503)...\n",
      "Fetching details for Textron (447/503)...\n",
      "Fetching details for Thermo Fisher Scientific (448/503)...\n",
      "Fetching details for TJX Companies (449/503)...\n",
      "Fetching details for Tractor Supply (450/503)...\n",
      "Fetching details for Trane Technologies (451/503)...\n",
      "Fetching details for TransDigm Group (452/503)...\n",
      "Fetching details for Travelers Companies (The) (453/503)...\n",
      "Fetching details for Trimble Inc. (454/503)...\n",
      "Fetching details for Truist Financial (455/503)...\n",
      "Fetching details for Tyler Technologies (456/503)...\n",
      "Fetching details for Tyson Foods (457/503)...\n",
      "Fetching details for U.S. Bancorp (458/503)...\n",
      "Fetching details for Uber (459/503)...\n",
      "Fetching details for UDR, Inc. (460/503)...\n",
      "Fetching details for Ulta Beauty (461/503)...\n",
      "Fetching details for Union Pacific Corporation (462/503)...\n",
      "Fetching details for United Airlines Holdings (463/503)...\n",
      "Fetching details for United Parcel Service (464/503)...\n",
      "Fetching details for United Rentals (465/503)...\n",
      "Fetching details for UnitedHealth Group (466/503)...\n",
      "Fetching details for Universal Health Services (467/503)...\n",
      "Fetching details for Valero Energy (468/503)...\n",
      "Fetching details for Ventas (469/503)...\n",
      "Fetching details for Veralto (470/503)...\n",
      "Fetching details for Verisign (471/503)...\n",
      "Fetching details for Verisk Analytics (472/503)...\n",
      "Fetching details for Verizon (473/503)...\n",
      "Fetching details for Vertex Pharmaceuticals (474/503)...\n",
      "Fetching details for Viatris (475/503)...\n",
      "Fetching details for Vici Properties (476/503)...\n",
      "Fetching details for Visa Inc. (477/503)...\n",
      "Fetching details for Vistra Corp. (478/503)...\n",
      "Fetching details for Vulcan Materials Company (479/503)...\n",
      "Fetching details for W. R. Berkley Corporation (480/503)...\n",
      "Fetching details for W. W. Grainger (481/503)...\n",
      "Fetching details for Wabtec (482/503)...\n",
      "Fetching details for Walgreens Boots Alliance (483/503)...\n",
      "Fetching details for Walmart (484/503)...\n",
      "Fetching details for Walt Disney Company (The) (485/503)...\n",
      "Fetching details for Warner Bros. Discovery (486/503)...\n",
      "Fetching details for Waste Management (487/503)...\n",
      "Fetching details for Waters Corporation (488/503)...\n",
      "Fetching details for WEC Energy Group (489/503)...\n",
      "Fetching details for Wells Fargo (490/503)...\n",
      "Fetching details for Welltower (491/503)...\n",
      "Fetching details for West Pharmaceutical Services (492/503)...\n",
      "Fetching details for Western Digital (493/503)...\n",
      "Fetching details for Weyerhaeuser (494/503)...\n",
      "Fetching details for Williams Companies (495/503)...\n",
      "Fetching details for Willis Towers Watson (496/503)...\n",
      "Fetching details for Wynn Resorts (497/503)...\n",
      "Fetching details for Xcel Energy (498/503)...\n",
      "Fetching details for Xylem Inc. (499/503)...\n",
      "Fetching details for Yum! Brands (500/503)...\n",
      "Fetching details for Zebra Technologies (501/503)...\n",
      "Fetching details for Zimmer Biomet (502/503)...\n",
      "Fetching details for Zoetis (503/503)...\n",
      "Enriched S&P 500 DataFrame has been saved to sp500_enriched.csv.\n"
     ]
    }
   ],
   "source": [
    "# Define new columns for additional company information\n",
    "new_columns = [\n",
    "    \"Industry\", \n",
    "    \"Revenue (Billions USD)\", \n",
    "    \"Net Income (Billions USD)\", \n",
    "    \"Number of Employees\", \n",
    "    \"Market Cap (Billions USD)\", \n",
    "    \"CEO\", \n",
    "    \"Founder(s)\", \n",
    "    \"Founded (Year)\"\n",
    "]\n",
    "\n",
    "# Initialize the new columns in the DataFrame with None\n",
    "for col in new_columns:\n",
    "    df[col] = None\n",
    "\n",
    "# Loop through each company and enrich the DataFrame\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        # Get the Wikipedia URL for the company\n",
    "        url = row['Link to Company Wikipedia page']\n",
    "        if not url:\n",
    "            print(f\"Skipping {row['Company Name']} (No URL available)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching details for {row['Company Name']} ({i + 1}/{len(df)})...\")\n",
    "\n",
    "        # Retrieve company information using the scraper function\n",
    "        company_info = get_company_info_with_key_people(url)\n",
    "        \n",
    "        # Update the DataFrame with the retrieved data\n",
    "        for col in new_columns:\n",
    "            df.at[i, col] = company_info.get(col, None)  # Use `.get` to handle missing keys gracefully\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data for {row['Company Name']}: {e}\")\n",
    "\n",
    "# Save the enriched DataFrame to a CSV file\n",
    "output_file = \"sp500_enriched.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Enriched S&P 500 DataFrame has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b882a-e73a-4b80-833e-f9f3329f536f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
